<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>face-detection-made-easy-with-azure-cognitive-services</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<p><span data-css-15b13by="" aria-hidden="false">Get started</span></p>
<p><span data-css-15b13by="" aria-hidden="false">Log in</span></p>
<p><img src="../../pluralsight.imgix.net/author/lg/6455207a-ea14-4964-af40-b569f06f122e.jpg" alt="Author avatar" class="jsx-3841407315" /></p>
<p>Douglas Starnes</p>
<h1 id="face-detection-made-easy-with-azure-cognitive-services">Face Detection Made Easy with Azure Cognitive Services</h1>
<h3 id="douglas-starnes">Douglas Starnes</h3>
<ul>
<li><p>Oct 29, 2020</p></li>
<li><p>8 Min read</p></li>
<li><p>1,478 Views</p></li>
<li><p>Oct 29, 2020</p></li>
<li><p><span class="jsx-3759398792" itemprop="timeRequired">8 Min</span> read</p></li>
<li><p>1,478 Views</p></li>
</ul>
<p><span class="jsx-3759398792"></span></p>
<p><span data-css-1997kh1="">Cloud</span></p>
<p><span class="jsx-3759398792"></span></p>
<p><span data-css-1997kh1="">Cloud Application Development</span></p>
<p><span class="jsx-3759398792"></span></p>
<p><span data-css-1997kh1="">Azure Cognitive Services</span></p>
<p><span class="jsx-3759398792"></span></p>
<p><span data-css-1997kh1="">Machine Learning and AI</span></p>
<p>Introduction</p>
<p>4</p>
<ul>
<li><a href="#module-introduction" class="menu-link">Introduction</a></li>
<li><a href="#module-setup" class="menu-link">Setup</a></li>
<li><a href="#module-usingthefaceservice" class="menu-link">Using the Face Service</a></li>
<li><a href="#module-otherattributes" class="menu-link">Other Attributes</a></li>
<li><a href="#module-wheretogofromhere" class="menu-link">Where to Go From Here</a></li>
<li><a href="#module-summary" class="menu-link">Summary</a></li>
<li><a href="#top" class="menu-link">Top</a></li>
</ul>
<h2 id="introduction">Introduction</h2>
<p>We always want to put a name with a face. The face is one of the easiest ways for humans to recognize someone they know. That’s because there are so many features that make a face unique. Can a computer detect and interpret faces the same way that a human does? The field of computer vision has been working on this. In many cases, the answer is yes! But it’s a difficult task to implement. That’s why Azure Cognitive Services offers the Face service. It exposes a pre-trained facial detection model via a REST API that you can integrate into any application.</p>
<p>There are actually two face services in Azure Cognitive Services. The Azure Computer Vision Service can detect different objects in images, including faces. However, it only returns limited data about the detected faces, such as age, gender, and the bounding rectangle. The Face Service will do much more. It to predicts age and gender, and it also detects facial features such as the location of the eyes and nose. It also attempts to interpret the emotion of the facial expression and score how happy or sad a person is. And it can recognize the identity of a person by the structure of their face. In this guide, we will discuss the Face Service and not the Computer Vision Service.</p>
<h2 id="setup">Setup</h2>
<p>To use the Face Service you’ll need an Azure account. Next, in the portal, click <strong>Create a Resource</strong> and search for Face. Click the <strong>Create</strong> button to create a new instance of the service. <embed src="../../pluralsight2.imgix.net/guides/c204e770-2b5c-4828-9a1a-dbe43c9154c7_01.html" /></p>
<p>Select a subscription and resource group. Select the region closest to you and choose a unique name for the instance. For the pricing tier, the Free F0 will be sufficient for a demo and won’t cost anything. Click <strong>Next</strong> to dismiss the rest of the screens and then <strong>Create</strong> after validation passes. <embed src="../../pluralsight2.imgix.net/guides/9a090fa2-56f9-4239-88bb-0ee4cf028c99_02.html" /></p>
<p>In a few minutes, you’ll have a new instance of the Face service. Click on the <strong>Go to resource</strong> button to see the detail of the instance.</p>
<p>In the sidebar on the left, click on <strong>Keys and Endpoint</strong>. You’ll be presented with two masked keys and an endpoint. <embed src="../../pluralsight2.imgix.net/guides/80d688d2-7a7d-4ff3-9f6d-c6bf4aa8cbfc_03.html" /></p>
<p>The keys are like passwords, thus they are hidden. These will identify the user of the service to Azure. You’ll send one of these keys when calling the endpoint of the service. The endpoint is just a URL. Copy one of the keys and the endpoint as you’ll need them soon. In your C# project, add the NuGet package <span class="jsx-3120878690"><code>Microsoft.Azure.CognitiveServices.Vision.Face.2.6.0-preview.1</code></span>, which is the latest release as of this guide. At the top of the <span class="jsx-3120878690"><code>Main</code></span> method, add variables for the <span class="jsx-3120878690"><code>key</code></span> and <span class="jsx-3120878690"><code>endpoint</code></span>.</p>
<pre><code>1var key = &quot;{YOUR_API_KEY}&quot;;
2var endpoint = &quot;{YOUR_ENDPOINT}&quot;;</code></pre>
<p>csharp</p>
<h2 id="using-the-face-service">Using the Face Service</h2>
<p>Create a <span class="jsx-3120878690"><code>FaceClient</code></span> from the <span class="jsx-3120878690"><code>Microsoft.Azure.CognitiveServices.Vison.Face</code></span> namespace. The <span class="jsx-3120878690"><code>FaceClient</code></span> accepts an <span class="jsx-3120878690"><code>ApiKeyServiceClientCredential</code></span> that uses the <span class="jsx-3120878690"><code>key</code></span> from the Azure portal to identify your account.</p>
<pre><code>1var faceClient = new FaceClient(
2 new ApiKeyServiceClientCredential(key)
3);</code></pre>
<p>csharp</p>
<p>The endpoint is set with a property on the <span class="jsx-3120878690"><code>FaceClient</code></span> instance.</p>
<pre><code>1faceClient.Endpoint = endpoint;</code></pre>
<p>csharp</p>
<p>There are a number of methods on the <span class="jsx-3120878690"><code>FaceClient</code></span> to detect faces. You might have a web application that uploads images from the user and sends the image data to the service. A simpler way that will be enough for this demo is to send the Face Service a URL of an image. Here is one from Unsplash: <a href="https://source.unsplash.com/pQV8dGHrOLU" class="uri">https://source.unsplash.com/pQV8dGHrOLU</a></p>
<p>This is a picture of a young woman, so let’s see if Azure agrees. Pass the URL of the image to the <span class="jsx-3120878690"><code>DetectWithUrlAsync</code></span> method. This method is async so it has to be awaited, and the <span class="jsx-3120878690"><code>Main</code></span> method must also be marked as <span class="jsx-3120878690"><code>async</code></span>.</p>
<pre><code>1static async Task Main(string[] args)
2{
3  // ...
4  var faces = await faceClient.Face.DetectWithUrlAsync(
5     &quot;https://source.unsplash.com/pQV8dGHrOLU&quot;
6  );
7}</code></pre>
<p>csharp</p>
<p>The <span class="jsx-3120878690"><code>faces</code></span> are a <span class="jsx-3120878690"><code>List</code></span> of <span class="jsx-3120878690"><code>DetectedFace</code></span>, each of which has a <span class="jsx-3120878690"><code>FaceAttributes</code></span> property from which we can get the predicted age and gender of the subject of the photo.</p>
<pre><code>1foreach (var face in faces) 
2{
3  Console.WriteLine($&quot;Age: {face.FaceAttributes.Age}, Gender: {face.FaceAttributes.Gender}&quot;);
4}</code></pre>
<p>csharp</p>
<p>There is a problem. If you try to run the application now, it will crash. You must explicitly tell the Face Service the attributes you wish it to return. The attributes you need are stored in a <span class="jsx-3120878690"><code>List</code></span> of <span class="jsx-3120878690"><code>FaceAttributeType</code></span>.</p>
<pre><code>1var returnedAttributes = new List&lt;FaceAttributeType?&gt;
2{
3  FaceAttributeType.Age, FaceAttributeType.Gender
4};</code></pre>
<p>csharp</p>
<p>The <span class="jsx-3120878690"><code>DetectWithUrlAsync</code></span> method accepts the <span class="jsx-3120878690"><code>FaceAttributes</code></span> in the <span class="jsx-3120878690"><code>returnFaceAttributes</code></span> parameter.</p>
<pre><code>1var faces = await faceClient.Face.DetectWithUrlAsync(
2  &quot;https://source.unsplash.com/pQV8dGHrOLU&quot;,
3  returnFaceAttributes: returnedAttributes
4);</code></pre>
<p>csharp</p>
<p>Running the application, Azure returns an age of 24 and a gender of female.</p>
<h2 id="other-attributes">Other Attributes</h2>
<p>The Face Services supports many more attributes. For example, add <span class="jsx-3120878690"><code>FaceAttributeType.Hair</code></span> to the <span class="jsx-3120878690"><code>returnFaceAttributes</code></span> list, and the <span class="jsx-3120878690"><code>Hair</code></span> property of the <span class="jsx-3120878690"><code>FaceAttributes</code></span> of the <span class="jsx-3120878690"><code>DetectedFace</code></span> will contain data about the hair, if any, associated with the face, such as the color.</p>
<pre><code>1foreach (var hairColor in face.FaceAttributes.Hair.HairColor)
2{
3  Console.WriteLine($&quot;Hair color: {hairColor.Color.ToString()}&quot;);
4}</code></pre>
<p>csharp</p>
<p>Why does the hair color contain more than one color? That’s because hair color is subjective, and sometimes people color their hair with multiple shades. So each hair color is accompanied by a <span class="jsx-3120878690"><code>Confidence</code></span> score and stored in descending order.</p>
<pre><code>1foreach (var hairColor in face.FaceAttributes.Hair.HairColor)
2{
3  Console.WriteLine($&quot;Hair color: {hairColor.Color.ToString()}, Confidence: {hairColor.Confidence}&quot;);
4}</code></pre>
<p>csharp</p>
<p>Azure will predict that the young lady’s hair is most likely brown followed by red. It is also very confident that her hair is not white, as it has a confidence score of 0.</p>
<p>If the <span class="jsx-3120878690"><code>HairColor</code></span> property has no predictions, it means the subject in the photo does not have any hair.</p>
<p>The service can also detect facial hair and glasses. See the documentation for more about those attributes.</p>
<p>Detecting emotion is also a feature of the Face Service. Add the <span class="jsx-3120878690"><code>Emotion</code></span> <span class="jsx-3120878690"><code>FaceAttributeType</code></span> to the list. The <span class="jsx-3120878690"><code>Emotion</code></span> property of the <span class="jsx-3120878690"><code>FaceAttributes</code></span> has eight properties, each for a different emotion:</p>
<ul>
<li><span class="jsx-3120878690"><code>Anger</code></span></li>
<li><span class="jsx-3120878690"><code>Contempt</code></span></li>
<li><span class="jsx-3120878690"><code>Disgust</code></span></li>
<li><span class="jsx-3120878690"><code>Fear</code></span></li>
<li><span class="jsx-3120878690"><code>Happiness</code></span></li>
<li><span class="jsx-3120878690"><code>Neutral</code></span></li>
<li><span class="jsx-3120878690"><code>Sadness</code></span></li>
<li><span class="jsx-3120878690"><code>Surprise</code></span></li>
</ul>
<p>Each of these has a score, not unlike the <span class="jsx-3120878690"><code>Confidence</code></span> score for the hair color.</p>
<pre><code>1Console.WriteLine($&quot;{face.FaceAttributes.Emotion.Anger&quot;});</code></pre>
<p>csharp</p>
<p>Evaluating each one will show that Azure predicts the subject’s emotion is most likely neutral.</p>
<h2 id="where-to-go-from-here">Where to Go From Here</h2>
<p>There is a difference between facial detection and facial recognition. This guide has demonstrated facial detection, which will look for any face. If you want to look for a specific face, that is when you use face recognition. You’ll need to have multiple pictures from different perspectives of any face you want to recognize. You’ll use those to train the service to distinguish between that face and others. The Face Service can also detect faces inside of a video stream in real time.</p>
<h2 id="summary">Summary</h2>
<p>The Azure Cognitive Services face service lets you integrate facial recognition or detection into any application, no computer vision knowledge required. This makes a lot of sense for devices like smartphones that have a camera built in. It would be simple to take the code explained in this guide and use it in a Xamarin application to select pictures of people who are smiling. Thanks for reading!</p>
<p>4</p>
<p><a href="https://www.pluralsight.com/product/paths"><span data-css-15b13by="" aria-hidden="false">LEARN MORE</span></a></p>
</body>
</html>
